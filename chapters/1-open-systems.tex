\documentclass[../thesis.tex]{subfiles}
\begin{document}

\chapter{Open quantum systems}\label{ch:open-quantum-systems}

\dropcap{S}{omebody} flips a coin. Which side will it land on? Physics should be
able to provide an answer to this question. All that we need to answer this
question is the initial state of the coin and the mechanics of the flipping
process. However, we do not know which side the coin starts on, so the best we
can do is assign probabilities to each side. Starting from heads, flipping the
coin will produce either heads or tails with some probabilities, and similar if
the coin starts as tails, though perhaps the probabilities are different. We may
then assign probabilities to the outcomes of the flipping operation (heads or
tails), given the initial belief for the probabilities of each starting side. In
doing this analysis, we have neglected all details about the atomic composition
of the coin and the details of how the coin is flipped. This situation suggests
a new way of looking at the coin. If we are only interested in determining the
side the coin lands on, then we may model the system with only the probabilities
of the different flip outcomes, and we do not need to consider the positions and
momenta of the atoms that make up the coin. Just as Newtonian mechanics
abstracts away the atomic details of the coin and only considers an effective
Newtonian system with an ideal rigid body, we may consider ``coin mechanics''
where we abstract away details and consider an ideal ``coin system.'' A coin
system would specify an initial ``coin state'' and the probabilities needed to
analyze the flipping operation. Such a probabilistic theory is more general than
classical mechanics, which requires deterministic operations.

In 1924, a similar situation was discovered in a beam of silver atoms by Otto
Stern and Walther Gerlach~\cite{gerlachUberRichtungsquantelungIm1924}. With the
apparatus in \cref{fig:silver-furnace}, silver atoms were vaporized in a
furnace, passed through collimators, subjected to a non-uniform magnetic field,
and then detected on a plate.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.75\linewidth]{silver-furnace}
  \caption{%
    The original Stern-Gerlach
    experiment~\cite{schmidt-bockingSternGerlachExperimentRevisited2016}.
  }\label{fig:silver-furnace}
\end{figure}
The initial state of a silver atom is thought to be random (isotropic) because
of the furnace and the lack of a reason to think otherwise, and the operation
being performed is simply that of waiting until the atom hits the plate.
Surprisingly, the plate looked like \cref{fig:stern-gerlach}.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.75\linewidth]{stern-gerlach}
  \caption{%
    Early detection plates from a postcard Gerlach sent to Niels Bohr
    {\small(Courtesy of the \href{https://www.nbarchive.dk}{Niels Bohr Archive}
    in Copenhagen)}.
  }\label{fig:stern-gerlach}
\end{figure}
With no magnet (left), the atoms are not deflected, yet with the magnet (right),
the atoms are separated cleanly into two beams. This happens for all
orientations of the magnet around the beam. As experiments of this type
improved, it became clear that the classical probability theory used in a coin
system was insufficient to describe which side a silver atom would be deflected
towards. Rather than coin mechanics, a new theory known as \term{quantum
mechanics} emerged. This theory uses a different mathematical formalism to
calculate the probabilities of outcomes, and provides some guidance on how to
represent physical systems within that formalism.

We will develop this quantum theory from the ground up.
\Cref{sec:math-form,sec:composite,sec:closed,sec:quantization} have some overlap
with the standard undergraduate curriculum. However, because we use a fully
general notion of the quantum state without any reference to a physical system,
the development is initially different from the usual approach that considers
the wavefunctions of particles. In particular, \cref{sec:composite} on composite
systems is not usually covered. After these preliminaries, we start to develop
the theory of open quantum systems in \cref{sec:open}.


\section{The mathematical formalism}\label{sec:math-form}

Different mathematical formalisms for quantum theory differ in how they
represent states and operations, but they agree on the assignment of
probabilities to outcomes. We will now give postulates for the widely used
Hilbert space description of the quantum probability theory.
\begin{post}\label{post:hilb}
  A quantum system is described by a separable complex Hilbert space
  $\hilb$.\footnote{%
    Since a quantum system is identified only by its dimension $d$, we may
    wonder which $d$-dimensional Hilbert space to assign. However, all finite
    $d$-dimensional (separable) complex Hilbert spaces are isometrically
    isomorphic to $\CC^d$, and all infinite-dimensional separable Hilbert spaces
    are isometrically isomorphic to $\ell^2$ (square-summable sequences) and
    to $L^2$ (square-integrable functions).
  }
\end{post}

\begin{post}\label{post:effects}
  An outcome corresponds to an \term{effect} $\opr{E}$, which is a Hermitian
  operator on $\hilb$ such that $\zopr \le \opr{E} \le \idopr$.\footnotemark%
\end{post}
\footnotetext{%
  The notation $\opr{A} \le \opr{B}$ means that $\mel{v}{\opr{A}}{v} \le
  \mel{v}{\opr{B}}{v}$ for all $v \in \hilb$.
}

\begin{post}\label{post:probability_measure}
  A state corresponds to a \term{probability measure} $P$ on effects. That is:
  \begin{enumerate}
    \item $0 \le P(\opr{E}) \le 1$ for all effects $\opr{E}$,
    \item $P(\idopr) = 1$,
    \item $P(\opr{E}_1 + \opr{E}_2 + \cdots) = P(\opr{E}_1) + P(\opr{E}_2)
      + \cdots$ for any sequence of events with $\opr{E}_1 + \opr{E}_2 + \cdots
      \le \idopr$.
  \end{enumerate}
\end{post}

\begin{post}\label{post:convex}
  States form a convex set. If $\sum_i p_i = 1$, the convex sum of states
  $\qty{P_i}$ is defined by
  \begin{equation}
    \qty(\sum_i p_i P_i)(\opr{E})
    = \sum_i p_i P_i(\opr{E}).
    \label{eq:convex}
  \end{equation}
  Such a combination is known as an \term{ensemble}.
\end{post}
Note that the convex structure of the set of quantum states is necessary for
consistency. One must obtain the same results when one makes two state
assignments, predicts outcomes for each, and averages the results, as when one
assigns the average state first and then predicts outcomes.

It is simple to prove that any probability measure $P$ on an effect
$\opr{E}$ may be represented by the \term{Born rule}
\begin{equation}
  P(\opr{E})
  = \tr(\dop\opr{E}),
  \label{eq:effect_probability}
\end{equation}
where $\dop \ge \zopr$ is a Hermitian operator known as a \term{density
  operator}~\cite{buschQuantumStatesGeneralized2003,
  buschOperationalQuantumPhysics1997}.\footnote{%
  The more specific case where effects are restricted to be projections $\op{v}$
  for $v \in \hilb$ is significantly harder, and is known as Gleason's
  theorem~\cite{gleasonMeasuresClosedSubspaces1975}.
}
\Cref{eq:effect_probability} implies that $\tr\dop = 1$ and that a convex sum of
states is represented by the same sum of density operators. The Born rule
uniquely identifies density operators with states, so we will use the term state
to refer to density operators from now on.

An \term{observable} result of an operation is described by an assignment of
each outcome $m$ to an effect $\opr{E}_m$, where $\sum_m \opr{E}_m = \idopr$.
Since effects are positive operators that determine the probabilities of each
outcome, such an observable is called a \term{positive operator valued measure}
(\textsc{povm}). The special case where the effects are projectors is called a
\term{projection valued measure} (\textsc{pvm}). A \textsc{pvm} with the maximum
number of outcomes may be conveniently represented by the Hermitian operator
\begin{equation}
  \opr{M}
  = \sum_m m \op{v_m}.
\end{equation}
By virtue of this definition, the expected value of the \textsc{pvm} is
\begin{align}
  \ev{\opr{M}}
  &= \sum_m m P(m) \\
  &= \sum_m m \tr(\dop \op{v_m}) \\
  &= \tr(\dop\qty(\sum_m m \op{v_m})) \\
  &= \tr(\dop\opr{M}).
\end{align}
From here on, most observables will be \textsc{pvm}s represented by Hermitian
operators.

We now describe how operations change states.
\begin{post}\label{post:operation}
  An \term{operation} with outcome $m$ is described by a map $\sopr{O}_m$. The
  state $\dop$ after the operation becomes
  \begin{equation}
    \dop_m'
    = P{(m)}^{-1} \sopr{O}_m(\dop).
    \label{eq:operation}
  \end{equation}
\end{post}
Since $\dop_m'$ must be a density operator, \cref{post:operation} implies that
$\sopr{O}_m\dop \ge \zopr$ and
\begin{equation}
  \tr\sopr{O}_m(\dop)
  = P(m)
  = \tr(\dop \opr{E}_m).
\end{equation}
If an operation is performed but the outcome is unknown, we may assign the state
\begin{equation}
  \dop'
  = \sum_m P(m) \dop_m'
  = \sum_m \sopr{O}_m(\dop),
  \label{eq:non-selective}
\end{equation}
so that the next outcome with effect $\opr{E}$ has the expected probability
\begin{align}
  P(\opr{E})
  &= \tr(\dop' \opr{E}) \\
  &= \sum_m P(m) \tr(\dop_m' \opr{E}) \\
  &= \sum_m P(m) P(\opr{E} \,|\, m).
\end{align}

The state of the ensemble $\dop = \sum_i p_i \dop_i$ after an operation with
outcome $m$ is
\begin{equation}
  \frac{\sopr{O}_m(\dop)}{\tr\sopr{O}_m(\dop)}
  = \sum_i P(i \,|\, m) \frac{\sopr{O}_m(\dop_i)}{\tr\sopr{O}_m(\dop_i)}
  \label{eq:ensemble-operation}
\end{equation}
By Bayes' theorem,
\begin{equation}
  P(i \,|\, m)
  = \frac{P(i) P(m \,|\, i)}{P(m)}
  = \frac{p_i \tr\sopr{O}_m(\dop_i)}{\tr\sopr{O}_m(\dop)}.
\end{equation}
Now \cref{eq:ensemble-operation} becomes
\begin{equation}
  \sopr{O}_m \qty(\sum_i p_i \dop_i)
  = \sum_i p_i \sopr{O}_m(\dop_i).
  \label{eq:convex-operation}
\end{equation}
Thus operations are convex linear.


\section{Composite systems}\label{sec:composite}

The success of physics lies in the apparent lack of causal connections between
phenomena separated in space and time. Different things are different, and the
actions of someone on the other side of the world have no immediate effect on an
experiment performed now. We then expect that some physical systems are composed
of a number of subsystems. The whole system may be affected as different parts
that each respond the same way as if nothing else was there.\footnote{%
  For example, we will later consider each spin in a spin chain to be a
  subsystem, since each spin may be separately affected. However, each of two
  electrons would not be a subsystem, since removal of one electron changes
  where the other electron is likely to be found.
}

Given a quantum system with Hilbert space $\hilb$, a decomposition into
\termalt{subsystem}{subsystems} is described by Hilbert spaces $\hilb_i$ with
$\prod_i\dim\hilb_i = \dim\hilb$ and maps $f_i$, $g_i$ such that
\begin{equation}
  \tr(\dop f_i(\opr{E}_i))
  = \tr(g_i(\dop) \opr{E}_i)
  \label{eq:trcompat}
\end{equation}
for any state $\dop$ on $\hilb$ and effect $\opr{E}_i$ on $\hilb_i$. The maps
$f_i$ lift an effect from the subsystem to the composite system, while the $g_i$
reduce a composite state to a subsystem state.

What are $f_i$ and $g_i$? We will first consider their action on states of
definite composition. Consider states $\dop_A$ and $\dop_B$ on $\hilb_A$ and
$\hilb_B$ where $\dim\hilb_A \dim\hilb_B = \dim\hilb$. How do we represent the
\term{product state} $\dop$, which satisfies $g_A(\dop) = \dop_A$ and $g_B(\dop)
= \dop_B$? Perhaps $\dop$ is just the pair $(\dop_A,\, \dop_B)$. By
\cref{post:convex}, a convex combination of such pairs is also a composite
state. However, suppose that $\dop_A = \sum_i \alpha_i \dop_i^A$ and $\dop_B =
\sum_j \beta_j \dop_j^B$. We mean the same state when we consider either an
ensemble of composites or a composite of ensembles, which is the equivalence
\begin{equation}
  \qty(\sum_i \alpha_i \dop_i^A,\, \sum_j \beta_j \dop_j^B)
  \sim \sum_{ij} \alpha_i \beta_j \qty(\dop_i^A,\, \dop_j^B)
  \label{eq:tensorequiv}
\end{equation}
on the composite states. Thus the product state is not a pair, but an
equivalence class $[(\dop_A,\, \dop_B)]$ of $(\bdd(\hilb_A) \times
\bdd(\hilb_B))/{\sim}$. These classes are called \termalt{tensor}{tensors}. The
product state equivalence class is written with the \term{tensor product} as
$\dop_A \tp \dop_B$, and the whole space is called $\bdd(\hilb_A) \tp
\bdd(\hilb_B) \iso \bdd(\hilb)$.\footnote{%
  Is this Hilbert space separable as required by \cref{post:hilb}? Yes, but
  later we will consider a bath described by an infinite tensor product of
  harmonic oscillators. Such a Hilbert space is not separable, but the subspace
  that is physically relevant is separable. Since we will neglect high-frequency
  modes anyway, it also suffices to truncate the product once the energies are
  sufficiently high. For more discussion,
  see~\cite[pp.~84--87]{streaterPCTSpinStatistics2000a}.
}
The same argument gives the \term{product effect} $\opr{E}_A \tp \opr{E}_B$. Yet
the same could be said for the operator $\dop_A\opr{E}_A$, which leads us to
define $(\dop_A \tp \dop_B)(\opr{E}_A \tp \opr{E}_B) = \dop_A\opr{E}_A \tp
\dop_B\opr{E}_B$.

What is $\tr(\opr{A} \tp \opr{B})$? Product effects represent independent
events. For the probabilities to multiply, we must have
\begin{equation}
  \tr(\opr{A} \tp \opr{B})
  = \tr\opr{A} \tr\opr{B}.
\end{equation}
Thus an effect $\opr{E}_A$ is lifted as $f_A(\opr{E}_A) = \opr{E}_A \tp \idopr$.

We now extend to non-product states, which are called \term{entangled} states.
Consider a map $f$ of the $f_i$ and the countable sum of events $\opr{E} =
\sum_a \opr{E}_a$. By \cref{eq:trcompat},
\begin{align}
  \tr\qty(\dop \sum_a f\qty(E_a))
  &= \sum_a \tr\qty(\dop f\qty(E_a)) \\
  &= \sum_a \tr\qty(g(\dop) E_a) \\
  &= \tr\qty(g(\dop) \sum_a E_a) \\
  &= \tr\qty(\dop f\qty(\sum_a E_a))
\end{align}
for all $\dop$. Thus $f$ is countably additive. If $\opr{E}_1 \le \opr{E}_2$,
then
\begin{align}
  0
  &\le \tr(g(\dop) \qty(\opr{E}_2 - \opr{E}_1)) \\
  &= \tr(\dop f\qty(\opr{E}_2 - \opr{E}_1)),
\end{align}
so $f\qty(\opr{E}_1) \le f\qty(\opr{E}_2)$. It then follows that the $f_i$ are
convex.\footnote{%
  The argument is the same as that for the real linearity of a probability
  measure on effects given in~\cite{buschQuantumStatesGeneralized2003}.
}
By symmetry, the same argument shows that the $g_i$ are convex.

The map $g_A$ is known as a \term{partial trace}. The partial
trace over $B$ of $\dop_A \tp \dop_B$ is
\begin{equation}
  g_A(\dop)
  = \tr_B(\dop_A \tp \dop_B)
  \defeq \dop_A \tr\dop_B
  = \dop_A,
\end{equation}
and is extended linearly to combinations of product states.


\section{Closed dynamics}\label{sec:closed}

Now that we have described the composition of quantum systems, how do they
change in time? We are often interested in the case where the information held
by the quantum state does not change. This is called a \term{closed} quantum
system. While all isolated physical systems are thought to correspond to closed
quantum systems, the converse is not true. For example, atomic spins subject to
external control from lasers are still closed systems.

The change in a closed system is the result of an operation $\sopr{O}$ with a
single, definite outcome. The operation $\sopr{O}$ is convex by
\cref{eq:convex-operation}. Since the information in the state $\dop$ cannot
change, $\sopr{O}$ must be invertible. Kadison's theorem\footnote{%
  Wigner's theorem on symmetries of pure states is a special
  case~\cite[p.~77]{morettiMathematicalFoundationsQuantum2016}. Many similar
  results hold, such as that only unitary transformations preserve the entropy
  (relative or
  not)~\cite{heEntropypreservingMapsQuantum2015,molnarMapsStatesPreserving2010}.
}
states that all such operations have the form
\begin{equation}
  \sopr{O}(\dop)
  = \opr{U}\dop\opr{U}^\dag,
  \label{eq:unitary-operation}
\end{equation}
where the operator $\opr{U}$ is either \term{unitary} ($\opr{U}^\dag\opr{U} =
\idopr$) or \term{antiunitary} ($\opr{U}^\dag\opr{U} =
-\idopr$)~\cite{morettiMathematicalFoundationsQuantum2016,bengtssonGeometryQuantumStates2017}.

In contexts like quantum computation or control, all that matters is the state
before and after the operation. To consider the notion of an isolated physical
system, we must relate the quantum state to the physical time. We then have an
operator $\opr{U}(t)$ which gives the state
\begin{equation}
  \dop(t)
  = \opr{U}(t)\dop(0)\opr{U}^\dag(t)
  \label{eq:unitary-evolution}
\end{equation}
as a function of time. We expect that $\opr{U}(t)$ changes
continuously\footnote{%
  More precisely, $\opr{U}(t)$ is \term{strongly continuous} if $\lim_{t \to
  t_0} \opr{U}(t)\ket{v} = \opr{U}(t_0)\ket{v}$ for all real $t_0$ and $\ket{v}
  \in \hilb$.
}
and satisfies
\begin{equation}
  \opr{U}(t + t')
  = \opr{U}(t) \opr{U}(t')
\end{equation}
for real $t$, $t'$. Then since $\opr{U}(0) = \idopr$ is unitary, $\opr{U}(t)$ is
unitary. We would like a description of $\opr{U}(t)$ that does not depend on
time. This is provided by Stone's
theorem~\cite{stoneOneParameterUnitaryGroups1932}, which states that there is a
Hermitian operator $\ham$ such that\footnote{%
  Stone's theorem is novel since it allows us to consider the time derivative of
  $\opr{U}(t)$, even though we only assume that the map $t \mapsto \opr{U}(t)$
  is strongly continuous. Von Neumann showed that the strong continuity
  requirement may be relaxed to only being weakly
  measurable~\cite{neumannUberSatzHerrn1932}.
}
\begin{equation}
  \opr{U}(t)
  = e^{-\im\ham t}.
\end{equation}
This allows us to differentiate \cref{eq:unitary-evolution} to find
\begin{align}
  \dot{\dop}
  &= \dot{\opr{U}}(t)\dop(0)\opr{U}^\dag(t)
  + \opr{U}(t)\dop(0)\dot{\opr{U}}^\dag(t) \\
  &= -\im\ham\qty(\opr{U}(t)\dop(0)\opr{U}^\dag(t))
  + \qty(\opr{U}(t)\dop(0)\opr{U}^\dag(t))\im\ham \\
  &= -\im\comm{\ham}{\dop},
  \label{eq:liouville}
\end{align}
which is known as the \termalt{Liouville equation}{Liouville} or \term{von
  Neumann equation}.\footnote{%
  \Cref{eq:liouville} is given in \term{natural units} where $\hbar = c = m_e =
  1$ and $\mu_0 = 4\pi$. Otherwise $\dot{\dop} = -\im\comm{\ham}{\dop}/\hbar$.
}

Given an observable $\opr{A}$, its expected value over time is
\begin{align}
  \ev{\opr{A}}
  &= \tr(\dop(t)\opr{A}) \\
  &= \tr(\opr{U}(t)\dop(0)\opr{U}^\dag(t)\opr{A}) \\
  &= \tr(\dop(0)\opr{U}^\dag(t)\opr{A}\opr{U}(t)).
\end{align}
This suggests that the state may be regarded as constant, while an observable
changes in time as
\begin{equation}
  \opr{A}_H(t)
  = \opr{U}^\dag(t)\opr{A}\opr{U}(t).
  \label{eq:heisenberg-picture}
\end{equation}
This perspective is known as the \term{Heisenberg picture}, and leads to the
analogous \term{Heisenberg equation of motion}
\begin{equation}
  \dot{\opr{A}}_H
  = -\im\comm{\opr{A}_H}{\ham}
  \label{eq:heisenberg-eom}
\end{equation}
for observables. For reference, the usual perspective where the state changes in
time is known as the \term{Schr\"odinger picture}.

\section{Canonical quantization}\label{sec:quantization}

The discussion of quantum theory thus far has been fully general. The Liouville
equation (\cref{eq:liouville}) specifies how a state $\dop$ changes in time,
given the Hilbert space for the system, the operator $\ham$, and the initial
state $\dop(0)$. How does one determine these quantities for a particular
physical system? We will only consider physical systems that can be modeled by
nonrelativistic classical mechanics. Consider a classical system with
generalized coordinates $q_i$ and momenta $p_i$. If the system has classical
Hamiltonian $H(\vq{q}, \vq{p})$, then Hamilton's equations of motion are
\begin{align}
  \dot{q_i} &= \pdv{H}{p_i} = \qty{q_i, H} \\
  \dot{p_i} &= -\pdv{H}{q_i} = \qty{p_i, H},
\end{align}
in terms of the \term{Poisson bracket}
\begin{equation}
  \qty{f, g}
  = \sum_i \qty(\pdv{f}{q_i}\pdv{g}{p_i} - \pdv{g}{q_i}\pdv{f}{p_i}).
  \label{eq:poisson-bracket}
\end{equation}
We notice that Hamilton's equations are similar to the Heisenberg equations of
motion
\begin{align}
  \dot{\opr{q}_i}
  &= -\im\comm{\opr{q}_i}{\ham} \\
  \dot{\opr{p}_i}
  &= -\im\comm{\opr{p}_i}{\ham},
\end{align}
where the time-evolution operator $\ham$ takes the place of the Hamiltonian.
This suggests the idea of a quantization map $Q$ that maps functions $f$ and $g$
on phase space to operators. We expect that $Q(1) = \idopr$, $Q(q_i) =
\opr{q}_i$ and $Q(p_i) = \opr{p}_i$. Then to obtain the Heisenberg equations of
motion we must require that
\begin{equation}
  Q(\qty{f, g})
  = -\im\comm{Q(f)}{Q(g)}.
  \label{eq:quantization-bracket}
\end{equation}
In particular, since $\qty{q_i, p_j} = \delta_{ij}$, $Q$ must yield the
\term{canonical commutation relations} (\textsc{ccr}s)
\begin{equation}
  \comm{\opr{q}_i}{\opr{p}_j}
  = \im\delta_{ij}.
  \label{eq:canonical-commutation}
\end{equation}
For the moment, consider a classical system with only one degree of
freedom.\footnote{%
  All the considerations to follow generalize naturally to many degrees of
  freedom.
}
One can show that the only possible quantization for polynomials in $q$ and $p$
with degree less than four is the \term{Weyl quantization}. This simply averages
over all possible operator orders.\footnote{%
  In general, the Weyl quantization of $f$ is
  \begin{equation}
    Q(f)
    = \exp(\frac{1}{2\im}\sum_i \pdv{}{\opr{q}_i}{\opr{p}_i})
    \hat{f}(\vecopr{q}, \vecopr{p}),
  \end{equation}
  where $\hat{f}$ is $f$ in the normal form where $\opr{q}_i$ always precedes
  $\opr{p}_i$~\cite{shewellFormationQuantumMechanicalOperators1959}.
}
For example,
\begin{equation}
  Q(3q p^2)
  = \opr{q}\opr{p}^2 + \opr{p}\opr{q}\opr{p} + \opr{p}^2 \opr{q}.
\end{equation}
What about a degree four polynomial like $q^2 p^2$? One may compute that
\begin{equation}
  q^2 p^2
  = \frac{1}{9}\qty{q^3, p^3}
  = \frac{1}{3}\qty{q^2 p, qp^2},
\end{equation}
yet
\begin{equation}
  \frac{1}{9}\comm{Q(q^3)}{Q(p^3)}
  \ne \frac{1}{3}\comm{Q(q^2 p)}{Q(qp^2)},
\end{equation}
so there is no quantization of $q^2 p^2$. This result on the nonexistence of a
general quantization map is known as Groenewold's
theorem~\cite[p.~272]{hallQuantumTheoryMathematicians2013}. Luckily, we will
only consider systems where the Weyl quantization satisfies
\cref{eq:quantization-bracket}, and we may put the issue of quantization aside.

Now we know that $\opr{q}$ and $\opr{p}$ must satisfy the \textsc{ccr}. But
what are they? Weyl showed that $\opr{q}$ and $\opr{p}$ must be operators on an
infinite-dimensional Hilbert
space~\cite{weylQuantenmechanikUndGruppentheorie1927}. The usual assignment for
square-integrable functions $f$ is $\opr{q}f(q) = qf(q)$ and $\opr{p}f(q) = -\im
f'(q)$, which satisfies the \textsc{ccr}. How do we know that this is the right
assignment? What if one should assign a different Hilbert space $\hilb$ with
other position and momentum operators $\opr{q}'$ and $\opr{p}'$? By Stone's
theorem, there are unitary operators $\opr{U}(t) = e^{\im t\opr{q}'}$ and
$\opr{V}(s) = e^{\im s\opr{p}'}$. Then a formal application of the
Baker-Campbell-Hausdorff (\textsc{bch}) formula\footnote{%
  Namely that if $\comm{\opr{A}}{\comm{\opr{A}}{\opr{B}}} =
  \comm{\opr{B}}{\comm{\opr{A}}{\opr{B}}} = \zopr$, then
  \begin{equation}
    e^{\opr{A}} e^{\opr{B}}
    = e^{\opr{A} + \opr{B} + \comm{\opr{A}}{\opr{B}}/2}.
    \label{eq:bch}
  \end{equation}
}
gives that
\begin{equation}
  \opr{U}(t)\opr{V}(s)
  = e^{-\im st}\opr{V}(s)\opr{U}(t),
  \label{eq:weyl-relation}
\end{equation}
which is known as the Weyl
relation~\cite[p.~281]{hallQuantumTheoryMathematicians2013}.\footnote{%
  Since the Weyl relation was derived through a merely formal procedure, not all
  operators satisfying the \textsc{ccr} satisfy the Weyl relation. The usual
  $\opr{q}$ and $\opr{p}$ do satisfy the Weyl relation, so we may as well
  stipulate that any putative operators $\opr{q}'$ and $\opr{p}'$ must satisfy
  it as well.
}
The Stone-von Neumann theorem\footnote{%
  The Stone-von Neumann theorem was also used to prove the equivalence between
  the Schr\"odinger equation and Heisenberg's matrix mechanics.
}
is that there is a unitary operator $\opr{T}:L^2(\RR) \to \hilb$ such that
\begin{align}
  \opr{T}^\dag \opr{U}(t) \opr{T} &= e^{\im t \opr{q}} \\
  \opr{T}^\dag \opr{V}(s) \opr{T} &= e^{\im s \opr{p}}.
\end{align}
Differentiating and setting $t = s = 0$ then gives that
\begin{align}
  \opr{T}^\dag \opr{q}' \opr{T} &= \opr{q} \\
  \opr{T}^\dag \opr{p}' \opr{T} &= \opr{p}.
\end{align}
Given a density operator $\dop$ on $L^2(\RR)$, we may assign a density operator
on $\hilb$ by $\dop' = \opr{T} \dop \opr{T}^\dag$, which satisfies that
\begin{align}
  \tr(\dop' \opr{q}') &= \tr(\dop \opr{q}) \\
  \tr(\dop' \opr{p}') &= \tr(\dop \opr{p}),
\end{align}
and similar for polynomials in $p$ and $q$. Thus the predictions of quantum
theory do not depend on the representation of a system's canonical coordinates,
and we are justified in making the usual assignment for $\opr{q}$ and $\opr{p}$.


\section{Open dynamics}\label{sec:open}

An \term{open system} is a quantum system where the information held by the
quantum state may change. We will consider only open quantum systems that model
interacting physical systems. First, a larger closed system $\hilb$ is
identified and separated into two subsystems: the open system $\hilb_S$ of
interest and the environment or bath $\hilb_B$ that the open system interacts
with. We know that the initial state of the open system is $\dop_0$. The system
is said to follow \term{open dynamics} if the state at time $t$ is determined by
the following procedure.

\begin{enumerate}
  \item The state $\dop_0$ is promoted to a state of the composite system
    according to an \term{assignment map} $\sopr{A}(\dop_0)$. A consistent
    assignment map should have the following intuitive
    properties:~\cite{alickiCommentReducedDynamics1995}
    \begin{enumerate}
      \item $\sopr{A}$ is convex,
      \item $\tr_B \sopr{A}(\dop_0) = \dop_0$,
      \item $\sopr{A}(\dop_0)$ is a density operator.
    \end{enumerate}

  \item The assigned composite state becomes $\dop(t) =
    \opr{U}(t)\sopr{A}(\dop_0)\opr{U}^\dag(t)$ as usual for a closed system.

  \item The state $\dop(t)$ is reduced to give the open system state $\dop_S(t)
    = \tr_B \dop(t)$.
\end{enumerate}
In summary, the state at time $t$ is
\begin{equation}
  \dop_S(t)
  = \tr_B(\opr{U}(t)\sopr{A}(\dop_0)\opr{U}^\dag(t)),
  \label{eq:reduced-dynamics}
\end{equation}
which we may express as the \term{dynamical map} $\sopr{V}(t) \dop_S(0) =
\dop_S(t)$. Note that property (b) of $\sopr{A}$ ensures that $\dop_S(0) =
\dop_0$, which is consistent.

One can show that the only consistent assignment maps for a two-dimensional
system are of the form $\sopr{A}(\dop_0) = \dop_0 \tp \dop_B$, where $\dop_B$ is
a constant density operator on $\hilb_B$~\cite{pechukasReducedDynamicsNeed1994}.
We will consider $\dop_B$ to be a stationary state of the bath, such as a
thermal state at some temperature. Why do we not require that the composite
state $\dop(t)$ is always assignable, remaining within the image of $\sopr{A}$?
This would make $\sopr{V}$ satisfy that
\begin{equation}
  \sopr{V}(t + s)
  = \sopr{V}(t)\sopr{V}(s).
  \label{eq:assignable-map}
\end{equation}
Since $\dop_B$ does not change in time, this requires that the system does not
interact with the bath. The only allowed open systems would be closed systems!
What is wrong with requiring the composite state to be assignable? The issue is
that interactions will inevitably entangle the system with the bath, causing one
to be unable to consider the composite as the two subsystems in the product
assignment.

However, we are interested in the reduced dynamics of the system, and what
happens on the timescale $\tau_R$ where the system changes appreciably. If the
timescale of the correlations in the bath is $\tau_C$, then from the perspective
of a system with $\tau_C \ll \tau_R$, the bath is effectively stationary. Thus
$\dop(t)$ is approximately assignable if we only aim to consider the
coarse-grained system dynamics. The notion of reduced dynamics only makes sense
on system timescales, and requires several conditions on
\cref{eq:reduced-dynamics} for the coarse-graining to be possible. Since the
system must be weakly coupled to the bath for the bath to remain approximately
stationary, these simplifications are collectively called the
\term{weak-coupling limit}.

This process will lead to a differential equation (\cref{eq:microlindblad}) for
$\dop_S$. It is worth mentioning that this equation, known as the Lindblad
equation, is in the general form for any map $\sopr{V}(t)$ on density matrices
that satisfies \cref{eq:assignable-map}, with the technical condition that it is
also completely positive.\footnote{%
  For any Hilbert space $\hilb'$, define the combined operation $\sopr{V}(t) \tp
  \idsopr$ by $(\sopr{V}(t) \tp \idsopr)(\opr{A} \tp \opr{B}) =
  \sopr{V}(t)\opr{A} \tp \opr{B}$ and extending linearly. We say that
  $\sopr{V}(t)$ is \term{completely positive} if $(\sopr{V}(t) \tp
  \idsopr)(\opr{C})$ is positive for every positive operator $\opr{C}$ on
  $\hilb_S \tp \hilb'$~\cite[p.~89]{opensys}.
}
This is shown in \cref{ch:lindblad}. On these grounds, it is often asserted that
all reduced dynamics must be completely positive. This is not the case if the
initial condition of the composite system is not a product state, and we have
argued that the notion of reduced dynamics does not make sense outside of the
weak-coupling limit. The debate concerning complete positivity remains a
contentious
issue~\cite{pechukasReducedDynamicsNeed1994,shajiWhoAfraidNot2005,cuffaroDebateConcerningProper2013}.


\section{The weak-coupling limit\label{sec:interaction}}

We will now determine the conditions on the Hamiltonian of the composite system
that give rise to reduced dynamics when the bath is in an equilibrium state
$\dop_B$. We decompose the Hamiltonian as
\begin{align}
  \ham
  &= \ham_0 + \ham_I \label{eq:H0HI} \\
  &= \ham_S \tp \idopr + \idopr \tp \ham_B + \ham_I,
\end{align}
where $\ham_S$ is the Hamiltonian of the system, $\ham_B$ is the Hamiltonian of
the bath, and $\ham_I$ is the interaction Hamiltonian between the system and the
bath. First, we will recast the dynamics of the composite system into a
convenient form. Recall the Heisenberg picture from \cref{sec:closed}. Given
\cref{eq:H0HI}, we may similarly decompose the expected value of an observable
$\opr{A}$ for the composite system. If we let
\begin{align}
  \opr{U}_0(t)
  &= e^{-\im\ham_0 t} \\
  \opr{U}_I(t)
  &= \opr{U}_0^\dag(t) \opr{U}(t),
\end{align}
then we may decompose the expected value as
\begin{align}
  \ev{\opr{A}}
  &= \tr(\opr{A} \opr{U}(t) \dop(0) \opr{U}^\dag(t)) \\
  &= \tr(\opr{U}_0^\dag(t) \opr{A} \opr{U}_0(t) \,
  \opr{U}_I(t) \dop(0) \opr{U}_I^\dag(t)).
\end{align}
This suggests that we define the time-dependent operators
\begin{align}
  \opr{A}_I(t)
  &= \opr{U}_0^\dag(t) \opr{A} \opr{U}_0(t)
  \label{eq:intobs} \\
  \dop_I(t)
  &= \opr{U}_I(t) \dop(0) \opr{U}_I^\dag(t)
  \label{eq:intdop}.
\end{align}
This perspective is known as the \term{interaction picture}, and the associated
equation of motion is
\begin{equation}
  \dot{\dop}_I
  = -\im\comm{\ham_I}{\dop_I}.
  \label{eq:intpic}
\end{equation}
We will use \cref{eq:intpic} in its integral form
\begin{equation}
  \dop_I(t)
  = \dop_I(0) - \im\int_0^t \dd{s} \comm{\ham_I(s)}{\dop_I(s)}.
  \label{eq:intpic-intform}
\end{equation}

It will also be helpful to relate the interaction Hamiltonian to transition
frequencies of the system as follows.\footnote{%
  This decomposition requires that the spectrum of $\ham_S$ is discrete.
}
First, we write a general interaction Hamiltonian as
\begin{equation}
  \ham_I
  = \sum_\alpha \opr{A}_\alpha \tp \opr{B}_\alpha,
\end{equation}
where $\opr{A}_\alpha$ and $\opr{B}_\alpha$ are Hermitian. If $E$ is an
eigenvalue of $\ham_S$, let $\opr{\Pi}(E)$ denote the projector onto the
eigenspace for $E$. Now we let
\begin{equation}
  \opr{A}_{\alpha}(\omega)
  = \sum_{E' - E = \omega} \opr{\Pi}(E)\opr{A}_\alpha\opr{\Pi}(E'),
  \label{eq:Aprojectors}
\end{equation}
which satisfy that
\begin{equation}
  \opr{A}_\alpha^\dag(\omega)
  = \opr{A}_\alpha(-\omega).
\end{equation}
By the completeness of the energy projectors,
\begin{align}
  \sum_\omega \opr{A}_\alpha(\omega)
  &= \sum_\omega
  \sum_{E' - E = \omega} \opr{\Pi}(E)\opr{A}_\alpha\opr{\Pi}(E') \\
  &= \sum_{E_1,\, E_2}
  \opr{\Pi}(E_1)\opr{A}_\alpha\opr{\Pi}(E_2) \\
  &= \opr{A}_\alpha.
\end{align}
The $\opr{A}_\alpha(\omega)$ also satisfy
\begin{equation}
  \comm{\ham_S}{\opr{A}_{\alpha}(\omega)}
  = -\omega\opr{A}_{\alpha}(\omega).
  \label{eq:Aomega}
\end{equation}
Using \cref{eq:Aomega} to commute past the exponential in \cref{eq:intobs}
establishes that the corresponding interaction picture operators are
\begin{equation}
  \opr{A}_\alpha^I(\omega)
  = e^{-\im\omega t} \opr{A}_{\alpha}(\omega).
\end{equation}
Thus the interaction Hamiltonian in the interaction picture is
\begin{equation}
  \ham_I(t)
  = \sum_{\alpha\omega} e^{-\im\omega t} \opr{A}_{\alpha}(\omega)
  \tp \opr{B}_\alpha^I(t),
  \label{eq:inthamdecomp}
\end{equation}
where by \cref{eq:intobs}
\begin{equation}
  \opr{B}_\alpha^I(t)
  = e^{\im\ham_B t} \opr{B}_\alpha e^{-\im\ham_B t}.
\end{equation}
From here on we will drop the superscript $I$ and consider all time-dependent
operators to be in the interaction picture. For example, $\dop_S(t)$ is the
reduced state of the system in the interaction picture.

Since we are interested in how fluctuations in different environment modes are
related, we will consider the \term{reservoir correlation functions}
\begin{equation}
  \ev{\opr{B}_\alpha^\dag(t)\opr{B}_\beta(t - s)}.
  \label{eq:corr}
\end{equation}
Because $\dop_B$ is a stationary state of the bath, the correlation functions do
not depend on time.\footnote{%
  To see this, we use the product rule, \cref{eq:heisenberg-eom}, and the fact
  that $\comm{\dop_B}{\ham_B} = \zopr$ to find that
  \begin{align}
    \dv{t} \ev{\opr{B}_\alpha^\dag(t)\opr{B}_\beta(t - s)}
    &= \im\ev{%
      \comm{\ham_B}{\opr{B}_\alpha^\dag(t)}\opr{B}_\beta(t - s)
      + \opr{B}_\alpha^\dag(t)\comm{\ham_B}{\opr{B}_\beta(t - s)}
    } \\
    &= \im\ev{%
      \ham_B\opr{B}_\alpha^\dag(t)\opr{B}_\beta(t - s)
      - \opr{B}_\alpha^\dag(t)\opr{B}_\beta(t - s)\ham_B
    } \\
    &= \im\tr(%
    \comm{\dop_B}{\ham_B} \opr{B}_\alpha^\dag(t)\opr{B}_\beta(t - s)
    ) \\
    &= 0.
  \end{align}
}
We may then express the correlation functions as
\begin{equation}
  \ev{\opr{B}_\alpha^\dag(s)\opr{B}_\beta(0)}
\end{equation}
and consider their one-sided Fourier transforms
\begin{align}
  \Gamma_{\alpha\beta}(\omega)
  &\coloneqq \int_0^\infty \dd{s} e^{\im\omega s}
  \ev{\opr{B}_\alpha^\dag(s)\opr{B}_\beta(0)}
  \label{eq:onegammas} \\
  &\eqqcolon
  \frac{1}{2}\gamma_{\alpha\beta}(\omega)
  + \im S_{\alpha\beta}(\omega),
  \label{eq:gammadecomp}
\end{align}
where the corresponding matrix $\mq{S} = (\mq{Γ} - \mq{Γ}^\dag) / 2\im$ is
Hermitian and the matrix corresponding to the full Fourier transforms
\begin{equation}
  \gamma_{\alpha\beta}(\omega)
  = \int_{-\infty}^\infty \dd{s} e^{\im\omega s}
  \ev{\opr{B}_\alpha^\dag(s)\opr{B}_\beta(0)}
  \label{eq:gammas}
\end{equation}
is positive.

With this setup, we may now move to the main derivation of the Lindblad equation
in the interaction picture. Applying \cref{eq:intpic} to
\cref{eq:intpic-intform} and tracing out the environment gives the closed
equation
\begin{equation}
  \dot{\dop}_S(t)
  = -\int_0^t \dd{s}
  \tr_B\comm{\ham_I(t)}{\comm{\ham_I(s)}{\dop_S(s) \tp \dop_B}}
  \label{eq:first-approx}
\end{equation}
for the system density operator. In doing so we have made two assumptions. The
first is the \term{Born approximation}, which states that $\dop_B$ is stationary
(in the coarse-grained sense mentioned previously):
\begin{equation}
  \dop(t)
  = \dop_S(t) \tp \dop_B.
\end{equation}
The second is the \term{weak-coupling approximation}, which states that
\begin{equation}
  \tr_B\comm{\ham_I(t)}{\dop(0)}
  = 0.
\end{equation}
Because
\begin{align}
  \tr_B\comm{\ham_I(t)}{\dop(0)}
  &= \sum_\alpha \qty(%
  \opr{A}_\alpha(t) \dop_S(t) \tr(B_\alpha(t) \dop_B)
  - \dop_S(t) \opr{A}_\alpha(t) \tr(\dop_B B_\alpha(t))
  ) \\
  &= \sum_\alpha \comm{\opr{A}_\alpha(t)}{\dop_S(t)} \ev{B_\alpha(t)},
\end{align}
this is equivalent to the statement that the reservoir averages of the
interactions vanish:
\begin{equation}
  \ev{\opr{B}_\alpha(t)} = 0.
\end{equation}

We would now like to perform a set of approximations that makes
\cref{eq:first-approx} depend only on $\dop_S(t)$, called the \term{Markov
approximation}. First, we suppose that $\dop_S(s) = \dop_S(t)$, so that the
time-evolution only depends on the present time. Then \cref{eq:first-approx}
becomes the \term{Redfield equation}
\begin{equation}
  \dot{\dop}_S(t)
  = -\int_0^t \dd{s}
  \tr_B\comm{\ham_I(t)}{\comm{\ham_I(s)}{\dop_S(t) \tp \dop_B}}.
  \label{eq:redfield}
\end{equation}
To simplify further, we make the substitution $s \mapsto t - s$ and set the
upper limit of the integral to infinity:
\begin{equation}
  \dot{\dop}_S
  = -\int_0^\infty \dd{s}
  \tr_B\comm{\ham_I(t)}{\comm{\ham_I(t - s)}{\dop_S(t) \tp \dop_B}}.
  \label{eq:infbornmarkov}
\end{equation}
The Markov approximation is justified when the reservoir correlation functions
(\cref{eq:corr}) vanish quickly over a time $\tau_C$ that is smaller than the
relaxation time $\tau_R$. Substituting \cref{eq:inthamdecomp} into
\cref{eq:infbornmarkov} and using \cref{eq:onegammas} gives
\begin{equation}
  \dot{\dop}_S
  = 2\herm \sum_{\alpha\beta\omega\omega'}
  e^{\im(\omega' - \omega)t}
  \Gamma_{\alpha\beta}(\omega) \qty(%
  \opr{A}_{\beta}(\omega) \dop_S \opr{A}_{\alpha}^\dag(\omega')
  - \opr{A}_{\alpha}^\dag(\omega') \opr{A}_{\beta}(\omega) \dop_S),
  \label{eq:decompsub}
\end{equation}
where $\herm\opr{C} \coloneqq (\opr{C} + \opr{C}^\dag) / 2$. We would like
\cref{eq:decompsub} to have the simple form $\dot{\dop}_S = \sopr{L}(\dop_S)$,
where $\sopr{L}$ is a time-independent \term{superoperator} called the
\term{Liouvillian}. If the typical times
\begin{equation}
  \tau_S = \abs{\omega' - \omega}^{-1}
  \qfor \omega' \ne \omega
\end{equation}
for system evolution are small compared to the relaxation time $\tau_R$, then
the contribution from the fast-oscillating terms of \cref{eq:decompsub} where
$\omega' \ne \omega$ may be neglected. This \term{rotating wave} or
\term{secular approximation} is analogous to how we consider the high-energy
position distribution in the infinite square well to be uniform, even though it
is actually a fast-oscillating function. We then obtain
\begin{equation}
  \dot{\dop}_S
  = 2\herm \sum_{\alpha\beta\omega}
  \Gamma_{\alpha\beta}(\omega) \qty(%
  \opr{A}_{\beta}(\omega) \dop_S \opr{A}_{\alpha}^\dag(\omega)
  - \opr{A}_{\alpha}^\dag(\omega) \opr{A}_{\beta}(\omega) \dop_S).
  \label{eq:rotwave}
\end{equation}
Now applying the decomposition of $\Gamma_{\alpha\beta}$ (\cref{eq:gammadecomp})
gives the interaction picture \term{Lindblad equation}
\begin{equation}
  \dot{\dop}_S
  = -\im\comm{\ham_{LS}}{\dop_S} + \sopr{D}(\dop_S)
  \coloneqq \sopr{L}(\dop_S),
  \label{eq:microlindblad}
\end{equation}
where the \term{Lamb shift Hamiltonian} is
\begin{equation}
  \ham_{LS}
  = \sum_{\alpha\beta\omega}
  S_{\alpha\beta}(\omega) \opr{A}_{\alpha}^\dag(\omega) \opr{A}_{\beta}(\omega)
  \label{eq:lamb-shift}
\end{equation}
and the \term{dissipator} is
\begin{equation}
  \sopr{D}(\dop_S)
  = \sum_{\alpha\beta\omega} \gamma_{\alpha\beta}(\omega) \qty(%
  \opr{A}_{\beta}(\omega) \dop_S \opr{A}_{\alpha}^\dag(\omega)
  - \frac{1}{2} \acomm{\opr{A}_{\alpha}^\dag(\omega)
  \opr{A}_{\beta}(\omega)}{\dop_S}).
  \label{eq:dissipator}
\end{equation}
To transform back to the Schr\"odinger picture, one only needs to add the system
Hamiltonian $\ham_S$ to $\ham_{LS}$. One may then diagonalize
$\gamma_{\alpha\beta}$ to put \cref{eq:microlindblad} into the standard form of
\cref{eq:lindblad}. In our examples $\gamma_{\alpha\beta}$ will already be
diagonal. In this case, we call the operators $\opr{A}_\alpha(\omega)$
(\cref{eq:Aprojectors}) in the dissipator the \term{jump operators} of the open
system.


\section{Relaxation to thermal equilibrium\label{sec:thermo}}

If the bath is in the \term{thermal state}
\begin{equation}
  \dop_B
  = \frac{e^{-\beta\ham_B}}{\tr e^{-\beta\ham_B}},
\end{equation}
then we expect that the system will generally relax from any initial
configuration to the thermal state
\begin{equation}
  \dop_\text{th}
  = \frac{e^{-\beta\ham_S}}{\tr e^{-\beta\ham_S}}.
\end{equation}
We will now prove that $\dop_\text{th}$ is a stationary state. First, we see
that the Lamb shift Hamiltonian commutes with the system Hamiltonian, since
\cref{eq:Aomega} implies that
\begin{equation}
  \comm*{\ham_S}{\opr{A}_{\alpha}^\dag(\omega) \opr{A}_{\beta}(\omega)}
  = \zopr.
\end{equation}
Thus $\dop_\text{th}$ is unchanged by the unitary
part of $\sopr{L}$, and may turn our attention towards showing that
$\sopr{D}(\dop_\text{th}) = \zopr$. We may also use \cref{eq:Aomega} to find
that
\begin{align}
  \dop_\text{th} \opr{A}_\alpha(\omega)
  &= e^{\beta\omega} \opr{A}_\alpha(\omega) \dop_\text{th}
  \label{eq:left-th} \\
  \dop_\text{th} \opr{A}_\alpha^\dag(\omega)
  &= e^{-\beta\omega} \opr{A}_\alpha^\dag(\omega) \dop_\text{th}.
  \label{eq:right-th}
\end{align}

We may rearrange the reservoir correlation functions to find that
\begin{align}
  \ev{\opr{B}_\alpha^\dag(t) \opr{B}_\beta(0)}
  &= {\qty(\tr e^{-\beta\ham_B})}^{-1}
  \tr(e^{-\beta\ham_B} \opr{B}_\alpha^\dag(t) \opr{B}_\beta(0)) \\
  &= {\qty(\tr e^{-\beta\ham_B})}^{-1}
  \tr(e^{-\beta\ham_B} e^{\im\ham_B t}\opr{B}_\alpha e^{-\im\ham_B t} \opr{B}_\beta) \\
  &= {\qty(\tr e^{-\beta\ham_B})}^{-1}
  \tr(e^{-\beta\ham_B} \opr{B}_\beta e^{\im\ham_B (t + \im\beta)} \opr{B}_\alpha
  e^{-\im\ham_B (t + \im\beta)}) \\
  &= \ev{\opr{B}_\beta(0) \opr{B}_\alpha^\dag(t + \im\beta)},
  \label{eq:kms}
\end{align}
which is known as the the \termalt{KMS boundary condition}{\textsc{kms} boundary
  condition}~\cite{kubo,martinschwinger}.\footnote{%
  The similarity between the thermal state $\dop_B \propto e^{-\beta\ham_B}$ and
  the time evolution operator $\opr{U}(t) = e^{-\im t \ham_B}$ invites the study
  of the correlation functions in complex time. It is called a boundary
  condition because of its relevance for the theory of thermodynamic Green
  functions~\cite{bechstedtThermodynamicGreenFunctions2015}.
}
Fourier-transforming \cref{eq:kms} gives a relation for $\gamma_{\alpha\beta}$
(\cref{eq:gammas}):
\begin{equation}
  \gamma_{\alpha\beta}(-\omega)
  = e^{-\beta\omega} \gamma_{\beta\alpha}(\omega).
  \label{eq:gamma-th}
\end{equation}
We may then use \cref{eq:left-th,eq:right-th,eq:gamma-th} to compute that the
dissipator is
\begin{align}
  \sopr{D}(\dop_\text{th})
  &= \sum_{\alpha\beta\omega} \gamma_{\alpha\beta}(\omega) \qty(%
  \opr{A}_{\beta}(\omega) \dop_\text{th} \opr{A}_{\alpha}^\dag(\omega)
  - \frac{1}{2} \acomm{\opr{A}_{\alpha}^\dag(\omega)
  \opr{A}_{\beta}(\omega)}{\dop_\text{th}}
  ) \\
  &= \sum_{\alpha\beta\omega} \gamma_{\alpha\beta}(\omega) \qty(%
  e^{-\beta\omega} \opr{A}_{\beta}(\omega) \opr{A}_{\alpha}^\dag(\omega)
  - \frac{1}{2} \opr{A}_{\alpha}^\dag(\omega) \opr{A}_{\beta}(\omega)
  - \frac{1}{2} \opr{A}_{\alpha}^\dag(\omega) \opr{A}_{\beta}(\omega)
  ) \dop_\text{th} \\
  &= \qty(%
  \sum_{\alpha\beta\omega} \gamma_{\alpha\beta}(\omega)
  e^{-\beta\omega} \opr{A}_{\beta}(\omega) \opr{A}_{\alpha}^\dag(\omega)
  - \sum_{\alpha\beta\omega} \gamma_{\alpha\beta}(\omega)
  \opr{A}_{\alpha}^\dag(\omega) \opr{A}_{\beta}(\omega)
  ) \dop_\text{th} \\
  &= \zopr.
\end{align}
Thus $\dot{\dop}_\text{th} = 0$.

\end{document}

